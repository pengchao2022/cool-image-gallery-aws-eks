name: Deploy Comic Website

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  CLUSTER_NAME: comic-website-prod
  PROJECT_NAME: comic-website
  ENVIRONMENT: prod
  NAMESPACE: comic-website
  TF_BACKEND_BUCKET: comic-website-tfstate-2024

jobs:
  terraform-infrastructure:
    name: "Terraform - Create Infrastructure"
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0

    - name: Terraform Init
      id: init
      run: |
        cd terraform
        terraform init \
          -backend-config="bucket=${{ env.TF_BACKEND_BUCKET }}" \
          -backend-config="key=terraform/state/terraform.tfstate" \
          -backend-config="region=${{ env.AWS_REGION }}" \
          -backend-config="encrypt=true" \
          -backend-config="dynamodb_table=comic-website-tfstate-lock"

    - name: Terraform Format
      id: fmt
      run: |
        cd terraform
        terraform fmt -check

    - name: Terraform Validate
      id: validate
      run: |
        cd terraform
        terraform validate

    - name: Terraform Plan
      id: plan
      run: |
        cd terraform
        terraform plan \
          -var="aws_region=${{ env.AWS_REGION }}" \
          -var="project_name=${{ env.PROJECT_NAME }}" \
          -var="environment=${{ env.ENVIRONMENT }}" \
          -var="db_password=${{ secrets.DB_PASSWORD }}" \
          -out=tfplan

    - name: Terraform Apply
      if: github.ref == 'refs/heads/main'
      run: |
        cd terraform
        terraform apply -auto-approve tfplan

    - name: Get AWS Account ID
      if: github.ref == 'refs/heads/main'
      run: |
        ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        echo "ACCOUNT_ID=$ACCOUNT_ID" >> $GITHUB_ENV
        echo "AWS Account ID: $ACCOUNT_ID"

    - name: Update kubeconfig
      if: github.ref == 'refs/heads/main'
      run: |
        cd terraform
        aws eks update-kubeconfig \
          --region ${{ env.AWS_REGION }} \
          --name ${{ env.CLUSTER_NAME }}

    - name: Setup Kubernetes tools
      if: github.ref == 'refs/heads/main'
      uses: azure/setup-kubectl@v3
      
    - name: Setup Helm with specific version
      if: github.ref == 'refs/heads/main'
      uses: azure/setup-helm@v3
      with:
        version: '3.12.0'

    - name: Install ALB Ingress Controller with OIDC
      if: github.ref == 'refs/heads/main'
      run: |
        # Add EKS charts repository
        helm repo add eks https://aws.github.io/eks-charts
        helm repo update
        
        # è·å– Terraform è¾“å‡º
        cd terraform
        VPC_ID=$(terraform output -raw vpc_id)
        ALB_ROLE_ARN=$(terraform output -raw alb_controller_role_arn)
        cd ..
        
        echo "ğŸ”§ Creating ALB Controller ServiceAccount with OIDC..."
        
        # æ–¹æ³•1: ä½¿ç”¨ printf åˆ›å»ºå¹²å‡€çš„ YAML æ–‡ä»¶
        printf 'apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: aws-load-balancer-controller\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-load-balancer-controller\n    app.kubernetes.io/component: controller\n  annotations:\n    eks.amazonaws.com/role-arn: %s\n' "$ALB_ROLE_ARN" > alb-serviceaccount.yaml
        
        # éªŒè¯ YAML æ–‡ä»¶
        echo "=== YAML æ–‡ä»¶å†…å®¹ ==="
        cat alb-serviceaccount.yaml
        echo "===================="
        
        # åº”ç”¨ ServiceAccount
        kubectl apply -f alb-serviceaccount.yaml
        
        echo "ğŸ“ Creating ALB Controller values file..."
        
        # åˆ›å»º Helm values æ–‡ä»¶
        cat > alb-values.yaml << 'EOF'
        clusterName: $CLUSTER_NAME
        serviceAccount:
          create: false
          name: aws-load-balancer-controller
        region: $AWS_REGION
        vpcId: $VPC_ID
        image:
          repository: 602401143452.dkr.ecr.$AWS_REGION.amazonaws.com/amazon/aws-load-balancer-controller
        replicaCount: 2
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        EOF
        
        # æ›¿æ¢å˜é‡
        sed -i "s/\$CLUSTER_NAME/$CLUSTER_NAME/g" alb-values.yaml
        sed -i "s/\$AWS_REGION/$AWS_REGION/g" alb-values.yaml
        sed -i "s/\$VPC_ID/$VPC_ID/g" alb-values.yaml
        
        echo "ğŸš€ Installing AWS Load Balancer Controller..."
        
        # å…ˆå¸è½½å¯èƒ½å­˜åœ¨çš„æ—§ç‰ˆæœ¬
        helm uninstall aws-load-balancer-controller -n kube-system 2>/dev/null || true
        
        # å®‰è£…æ–°ç‰ˆæœ¬
        helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
          -n kube-system \
          -f alb-values.yaml \
          --version 1.6.1 \
          --wait
        
        echo "â³ Waiting for ALB Controller pods to be ready..."
        sleep 30
        
        # ç­‰å¾… Pod å°±ç»ª
        kubectl wait --for=condition=ready pod \
          -l app.kubernetes.io/name=aws-load-balancer-controller \
          -n kube-system \
          --timeout=300s
        
        echo "âœ… ALB Controller installed successfully with OIDC!"
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        rm -f alb-serviceaccount.yaml alb-values.yaml

  deploy-applications:
    name: "Deploy Applications to EKS"
    runs-on: ubuntu-latest
    needs: terraform-infrastructure
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig \
          --region ${{ env.AWS_REGION }} \
          --name ${{ env.CLUSTER_NAME }}

    - name: Setup Kubernetes tools
      uses: azure/setup-kubectl@v3

    - name: Setup Helm for applications
      uses: azure/setup-helm@v3
      with:
        version: '3.12.0'

    - name: Get Terraform Outputs
      run: |
        cd terraform
        DB_HOST=$(terraform output -raw rds_endpoint)
        S3_BUCKET_NAME=$(terraform output -raw s3_bucket_name)
        BACKEND_ECR_URL=$(terraform output -raw backend_ecr_repository_url)
        FRONTEND_ECR_URL=$(terraform output -raw frontend_ecr_repository_url)
        echo "DB_HOST=$DB_HOST" >> $GITHUB_ENV
        echo "S3_BUCKET_NAME=$S3_BUCKET_NAME" >> $GITHUB_ENV
        echo "BACKEND_ECR_URL=$BACKEND_ECR_URL" >> $GITHUB_ENV
        echo "FRONTEND_ECR_URL=$FRONTEND_ECR_URL" >> $GITHUB_ENV

    - name: Get AWS Account ID
      run: |
        ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        echo "ACCOUNT_ID=$ACCOUNT_ID" >> $GITHUB_ENV
        echo "AWS Account ID: $ACCOUNT_ID"

    - name: Login to ECR
      run: |
        aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin $ACCOUNT_ID.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com

    - name: Build and Push Backend Docker Image
      run: |
        echo "ğŸ—ï¸ Building backend Docker image..."
        cd backend
        docker build -t $BACKEND_ECR_URL:${GITHUB_SHA:0:8} .
        echo "ğŸš€ Pushing backend image to ECR..."
        docker push $BACKEND_ECR_URL:${GITHUB_SHA:0:8}
        cd ..
        echo "âœ… Backend image pushed: $BACKEND_ECR_URL:${GITHUB_SHA:0:8}"

    - name: Build and Push Frontend Docker Image
      run: |
        echo "ğŸ—ï¸ Building frontend Docker image..."
        cd frontend
        docker build -t $FRONTEND_ECR_URL:${GITHUB_SHA:0:8} .
        echo "ğŸš€ Pushing frontend image to ECR..."
        docker push $FRONTEND_ECR_URL:${GITHUB_SHA:0:8}
        cd ..
        echo "âœ… Frontend image pushed: $FRONTEND_ECR_URL:${GITHUB_SHA:0:8}"

    - name: Setup Kubernetes Secrets
      run: |
        echo "ğŸ” Setting up Kubernetes secrets..."
        
        # åˆ›å»ºå‘½åç©ºé—´ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        kubectl create namespace ${{ env.NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -
        
        # ä½¿ç”¨ printf åˆ›å»ºå¹²å‡€çš„ Secret æ–‡ä»¶
        printf 'apiVersion: v1\nkind: Secret\nmetadata:\n  name: rds-secret\n  namespace: %s\ntype: Opaque\nstringData:\n  host: "%s"\n  port: "5432"\n  username: "comicadmin"\n  database: "comicdb"\n  password: "%s"\n' "$NAMESPACE" "$DB_HOST" "${{ secrets.DB_PASSWORD }}" > rds-secret.yaml
        
        printf 'apiVersion: v1\nkind: Secret\nmetadata:\n  name: backend-secrets\n  namespace: %s\ntype: Opaque\nstringData:\n  JWT_SECRET: "%s"\n  AWS_ACCESS_KEY_ID: "%s"\n  AWS_SECRET_ACCESS_KEY: "%s"\n  S3_BUCKET_NAME: "%s"\n' "$NAMESPACE" "${{ secrets.JWT_SECRET || 'default-jwt-secret-change-in-production' }}" "${{ secrets.AWS_ACCESS_KEY_ID }}" "${{ secrets.AWS_SECRET_ACCESS_KEY }}" "$S3_BUCKET_NAME" > backend-secrets.yaml
        
        kubectl apply -f rds-secret.yaml
        kubectl apply -f backend-secrets.yaml
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        rm -f rds-secret.yaml backend-secrets.yaml
        
        echo "âœ… Kubernetes secrets created successfully"

    - name: Deploy Applications to EKS
      run: |
        echo "ğŸš€ Deploying applications to EKS..."
        
        # æ›´æ–°éƒ¨ç½²æ–‡ä»¶ä¸­çš„é•œåƒæ ‡ç­¾
        if [ -f "k8s-manifests/deployments/backend-deployment.yaml" ]; then
          sed -i "s|latest|${GITHUB_SHA:0:8}|g" k8s-manifests/deployments/backend-deployment.yaml
        fi
        
        if [ -f "k8s-manifests/deployments/frontend-deployment.yaml" ]; then
          sed -i "s|latest|${GITHUB_SHA:0:8}|g" k8s-manifests/deployments/frontend-deployment.yaml
        fi
        
        # åº”ç”¨æ‰€æœ‰ Kubernetes é…ç½®
        if [ -d "k8s-manifests" ]; then
          kubectl apply -k k8s-manifests/
        else
          echo "âš ï¸ k8s-manifests directory not found, skipping kustomize apply"
        fi
        
        echo "âœ… Applications deployed to EKS"

    - name: Wait for Deployments
      run: |
        echo "â³ Waiting for deployments to be ready..."
        kubectl wait --for=condition=available --timeout=600s deployment/backend-deployment -n ${{ env.NAMESPACE }} || true
        kubectl wait --for=condition=available --timeout=600s deployment/frontend-deployment -n ${{ env.NAMESPACE }} || true
        echo "âœ… All deployments are ready"

    - name: Verify Deployment
      run: |
        echo "ğŸ“Š Deployment Status:"
        echo "=== Deployments ==="
        kubectl get deployments -n ${{ env.NAMESPACE }} || true
        
        echo "=== Pods ==="
        kubectl get pods -n ${{ env.NAMESPACE }} -o wide || true
        
        echo "=== Services ==="
        kubectl get services -n ${{ env.NAMESPACE }} || true
        
        echo "=== Ingress ==="
        kubectl get ingress -n ${{ env.NAMESPACE }} || true

    - name: Health Check
      run: |
        echo "ğŸ” Performing health check..."
        
        # ç­‰å¾… ALB åˆ›å»º
        sleep 30
        
        ALB_URL=$(kubectl get ingress comic-website-ingress -n ${{ env.NAMESPACE }} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "pending")
        
        if [ "$ALB_URL" != "pending" ] && [ "$ALB_URL" != "" ]; then
          echo "ğŸŒ ALB URL: http://$ALB_URL"
          
          # é‡è¯•å¥åº·æ£€æŸ¥
          for i in {1..10}; do
            if curl -f http://$ALB_URL/health || curl -f http://$ALB_URL; then
              echo "âœ… Health check passed!"
              break
            else
              echo "âš ï¸ Health check attempt $i failed, retrying in 10 seconds..."
              sleep 10
            fi
          done
        else
          echo "â° ALB is still being created, check AWS console for progress"
        fi