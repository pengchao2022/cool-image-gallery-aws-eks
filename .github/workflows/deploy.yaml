name: Deploy Comic Website

on:
  push:
    branches: [main]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  CLUSTER_NAME: comic-website-prod
  PROJECT_NAME: comic-website
  ENVIRONMENT: prod
  NAMESPACE: comic-website
  TF_BACKEND_BUCKET: comic-website-tfstate-2024

jobs:
  terraform-infrastructure:
    name: "Terraform - Create Infrastructure"
    runs-on: ubuntu-latest
    environment: production
    outputs:
      backend_ecr_url: ${{ steps.terraform-outputs.outputs.backend_ecr_url }}
      frontend_ecr_url: ${{ steps.terraform-outputs.outputs.frontend_ecr_url }}
      rds_endpoint: ${{ steps.terraform-outputs.outputs.rds_endpoint }}
      rds_port: ${{ steps.terraform-outputs.outputs.rds_port }}
      rds_username: ${{ steps.terraform-outputs.outputs.rds_username }}
      rds_database: ${{ steps.terraform-outputs.outputs.rds_database }}
      s3_bucket_name: ${{ steps.terraform-outputs.outputs.s3_bucket_name }}
      s3_bucket_region: ${{ steps.terraform-outputs.outputs.s3_bucket_region }}
      alb_controller_role_arn: ${{ steps.terraform-outputs.outputs.alb_controller_role_arn }}
      backend_role_arn: ${{ steps.terraform-outputs.outputs.backend_role_arn }}
      frontend_role_arn: ${{ steps.terraform-outputs.outputs.frontend_role_arn }}
      alb_url: ${{ steps.terraform-outputs.outputs.alb_url }}

    steps:
      - name: üß© Checkout code
        uses: actions/checkout@v4

      - name: üîë Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: üèó Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: ‚öôÔ∏è Terraform Init
        run: |
          cd terraform
          terraform init \
            -backend-config="bucket=${{ env.TF_BACKEND_BUCKET }}" \
            -backend-config="key=terraform/state/terraform.tfstate" \
            -backend-config="region=${{ env.AWS_REGION }}" \
            -backend-config="encrypt=true" \
            -backend-config="dynamodb_table=comic-website-tfstate-lock"

      - name: ‚úÖ Terraform Validate
        run: |
          cd terraform
          terraform validate

      - name: üöÄ Terraform Plan and Apply
        run: |
          cd terraform
          terraform plan -out=tfplan \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="project_name=${{ env.PROJECT_NAME }}" \
            -var="environment=${{ env.ENVIRONMENT }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}"
          terraform apply -auto-approve tfplan

      - name: üìã Get Terraform Outputs
        id: terraform-outputs
        run: |
          cd terraform
          terraform output -json > outputs.json
          
          BACKEND_ECR_URL=$(jq -r '.backend_repository_url.value // empty' outputs.json)
          FRONTEND_ECR_URL=$(jq -r '.frontend_repository_url.value // empty' outputs.json)
          RDS_ENDPOINT=$(jq -r '.rds_endpoint.value // empty' outputs.json)
          RDS_PORT=$(jq -r '.rds_port.value // "5432"' outputs.json)
          RDS_USERNAME=$(jq -r '.rds_username.value // "comicadmin"' outputs.json)
          RDS_DATABASE=$(jq -r '.rds_database_name.value // "comicdb"' outputs.json)
          S3_BUCKET_NAME=$(jq -r '.s3_bucket_name.value // empty' outputs.json)
          S3_BUCKET_REGION=$(jq -r '.s3_bucket_region.value // empty' outputs.json)
          ALB_CONTROLLER_ROLE_ARN=$(jq -r '.alb_controller_role_arn.value // empty' outputs.json)
          BACKEND_ROLE_ARN=$(jq -r '.backend_role_arn.value // empty' outputs.json)
          FRONTEND_ROLE_ARN=$(jq -r '.frontend_role_arn.value // empty' outputs.json)
          ALB_URL=$(jq -r '.alb_url.value // empty' outputs.json)
          
          echo "backend_ecr_url=$BACKEND_ECR_URL" >> $GITHUB_OUTPUT
          echo "frontend_ecr_url=$FRONTEND_ECR_URL" >> $GITHUB_OUTPUT
          echo "rds_endpoint=$RDS_ENDPOINT" >> $GITHUB_OUTPUT
          echo "rds_port=$RDS_PORT" >> $GITHUB_OUTPUT
          echo "rds_username=$RDS_USERNAME" >> $GITHUB_OUTPUT
          echo "rds_database=$RDS_DATABASE" >> $GITHUB_OUTPUT
          echo "s3_bucket_name=$S3_BUCKET_NAME" >> $GITHUB_OUTPUT
          echo "s3_bucket_region=$S3_BUCKET_REGION" >> $GITHUB_OUTPUT
          echo "alb_controller_role_arn=$ALB_CONTROLLER_ROLE_ARN" >> $GITHUB_OUTPUT
          echo "backend_role_arn=$BACKEND_ROLE_ARN" >> $GITHUB_OUTPUT
          echo "frontend_role_arn=$FRONTEND_ROLE_ARN" >> $GITHUB_OUTPUT
          echo "alb_url=$ALB_URL" >> $GITHUB_OUTPUT

          # ÊòæÁ§∫ Terraform ËæìÂá∫ÁöÑÈáçË¶Å‰ø°ÊÅØ
          echo "=== Terraform Outputs ==="
          echo "Backend ECR URL: $BACKEND_ECR_URL"
          echo "Frontend ECR URL: $FRONTEND_ECR_URL"
          echo "RDS Endpoint: $RDS_ENDPOINT"
          echo "S3 Bucket: $S3_BUCKET_NAME"
          echo "ALB URL: $ALB_URL"

      - name: ‚ò∏Ô∏è Update kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.CLUSTER_NAME }}

  build-and-push-images:
    name: "Build and Push Docker Images"
    runs-on: ubuntu-latest
    needs: terraform-infrastructure
    environment: production
    if: needs.terraform-infrastructure.result == 'success'
    
    outputs:
      backend_image: ${{ steps.build-backend.outputs.image_tag }}
      frontend_image: ${{ steps.build-frontend.outputs.image_tag }}

    steps:
      - name: üß© Checkout code
        uses: actions/checkout@v4

      - name: üîë Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: üîç Get AWS Account ID and ECR Registry
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          echo "ACCOUNT_ID=$ACCOUNT_ID" >> $GITHUB_ENV
          ECR_REGISTRY="$ACCOUNT_ID.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com"
          echo "ECR_REGISTRY=$ECR_REGISTRY" >> $GITHUB_ENV

      - name: üîê Login to ECR
        run: |
          aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin $ECR_REGISTRY

      - name: üîç Set ECR URLs
        run: |
          echo "BACKEND_ECR_URL=${{ needs.terraform-infrastructure.outputs.backend_ecr_url }}" >> $GITHUB_ENV
          echo "FRONTEND_ECR_URL=${{ needs.terraform-infrastructure.outputs.frontend_ecr_url }}" >> $GITHUB_ENV

      - name: üèó Check if Backend Image Exists
        id: check-backend
        run: |
          IMAGE_TAG="${GITHUB_SHA:0:8}"
          BACKEND_IMAGE="$BACKEND_ECR_URL:$IMAGE_TAG"
          if docker manifest inspect $BACKEND_IMAGE > /dev/null 2>&1; then
            echo "image_exists=true" >> $GITHUB_OUTPUT
            echo "image_tag=$BACKEND_IMAGE" >> $GITHUB_OUTPUT
          else
            echo "image_exists=false" >> $GITHUB_OUTPUT
            echo "image_tag=$BACKEND_IMAGE" >> $GITHUB_OUTPUT
          fi

      - name: üß± Build Backend Image (if needed)
        id: build-backend
        if: steps.check-backend.outputs.image_exists == 'false'
        run: |
          cd backend
          IMAGE_TAG="${GITHUB_SHA:0:8}"
          BACKEND_IMAGE="$BACKEND_ECR_URL:$IMAGE_TAG"
          echo "Building and pushing backend image: $BACKEND_IMAGE"
          docker build -t $BACKEND_IMAGE .
          docker push $BACKEND_IMAGE
          echo "image_tag=$BACKEND_IMAGE" >> $GITHUB_OUTPUT

      - name: üé® Build Frontend Image
        id: build-frontend
        run: |
          cd frontend
          IMAGE_TAG="${GITHUB_SHA:0:8}"
          FRONTEND_IMAGE="$FRONTEND_ECR_URL:$IMAGE_TAG"
          echo "Building and pushing frontend image: $FRONTEND_IMAGE"
          docker build -t $FRONTEND_IMAGE .
          docker push $FRONTEND_IMAGE
          echo "image_tag=$FRONTEND_IMAGE" >> $GITHUB_OUTPUT

  deploy-applications:
    name: "Deploy Applications to EKS"
    runs-on: ubuntu-latest
    needs: 
      - terraform-infrastructure
      - build-and-push-images
    environment: production
    if: needs.terraform-infrastructure.result == 'success'

    steps:
      - name: üß© Checkout code
        uses: actions/checkout@v4

      - name: üîë Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: ‚ò∏Ô∏è Update kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.CLUSTER_NAME }}

      - name: üß∞ Setup kubectl
        run: |
          sudo snap install kubectl --classic

      - name: üîß Install envsubst
        run: |
          sudo apt-get update
          sudo apt-get install -y gettext-base

      - name: üîß Update Service Account Role ARNs
        run: |
          ALB_ROLE_ARN="${{ needs.terraform-infrastructure.outputs.alb_controller_role_arn }}"
          BACKEND_ROLE_ARN="${{ needs.terraform-infrastructure.outputs.backend_role_arn }}"
          FRONTEND_ROLE_ARN="${{ needs.terraform-infrastructure.outputs.frontend_role_arn }}"
          
          sed -i "s|ALB_ROLE_ARN_PLACEHOLDER|$ALB_ROLE_ARN|g" k8s/service-accounts/alb-service-account.yaml
          sed -i "s|BACKEND_ROLE_ARN_PLACEHOLDER|$BACKEND_ROLE_ARN|g" k8s/service-accounts/backend-service-account.yaml
          sed -i "s|FRONTEND_ROLE_ARN_PLACEHOLDER|$FRONTEND_ROLE_ARN|g" k8s/service-accounts/frontend-service-account.yaml

      - name: üîß Apply ALB Controller ServiceAccount
        run: |
          kubectl delete serviceaccount aws-load-balancer-controller -n kube-system --ignore-not-found=true
          kubectl apply -f k8s/service-accounts/alb-service-account.yaml

      - name: üîÑ Restart ALB Controller
        run: |
          kubectl rollout restart deployment/aws-load-balancer-controller -n kube-system
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=aws-load-balancer-controller -n kube-system --timeout=300s

      - name: üóÉ Create Namespace
        run: |
          kubectl create namespace ${{ env.NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

      - name: üîß Update Kubernetes Secrets
        run: |
          export RDS_ENDPOINT="${{ needs.terraform-infrastructure.outputs.rds_endpoint }}"
          export RDS_PORT="${{ needs.terraform-infrastructure.outputs.rds_port }}"
          export RDS_USERNAME="${{ needs.terraform-infrastructure.outputs.rds_username }}"
          export RDS_DATABASE="${{ needs.terraform-infrastructure.outputs.rds_database }}"
          export JWT_SECRET="${{ secrets.JWT_SECRET }}"
          export RDS_HOST=$(echo "$RDS_ENDPOINT" | cut -d':' -f1)
          export RDS_PASSWORD="${{ secrets.DB_PASSWORD }}"
          export S3_BUCKET_NAME="${{ needs.terraform-infrastructure.outputs.s3_bucket_name }}"
          export AWS_REGION="${{ env.AWS_REGION }}"
          
          envsubst < k8s/configs/rds-secret.yaml > k8s/configs/rds-secret.yaml.tmp
          mv k8s/configs/rds-secret.yaml.tmp k8s/configs/rds-secret.yaml
          
          envsubst < k8s/configs/backend-secret.yaml > k8s/configs/backend-secret.yaml.tmp
          mv k8s/configs/backend-secret.yaml.tmp k8s/configs/backend-secret.yaml
          
          envsubst < k8s/configs/s3-secret.yaml > k8s/configs/s3-secret.yaml.tmp
          mv k8s/configs/s3-secret.yaml.tmp k8s/configs/s3-secret.yaml

      - name: üöÄ Deploy Resources (excluding Deployments)
        run: |
          cd k8s
          # Â∫îÁî®ÊâÄÊúâËµÑÊ∫êÔºåÈô§‰∫Ü Deployments
          kubectl apply -f namespaces/comic-website.yaml
          kubectl apply -f service-accounts/alb-service-account.yaml
          kubectl apply -f service-accounts/backend-service-account.yaml
          kubectl apply -f service-accounts/frontend-service-account.yaml
          kubectl apply -f configs/backend-config.yaml
          kubectl apply -f configs/frontend-config.yaml
          kubectl apply -f configs/rds-secret.yaml
          kubectl apply -f configs/backend-secret.yaml
          kubectl apply -f configs/s3-secret.yaml
          kubectl apply -f service/backend-service.yaml
          kubectl apply -f service/frontend-service.yaml
          kubectl apply -f networking/alb-ingress-class.yaml
          kubectl apply -f networking/alb-ingress.yaml

      - name: üöÄ Deploy or Replace Deployments
        run: |
          cd k8s
          # Ê£ÄÊü• Deployment ÊòØÂê¶Â≠òÂú®ÔºåÂ¶ÇÊûúÂ≠òÂú®ÂàôÊõøÊç¢ÔºåÂê¶ÂàôÂàõÂª∫
          if kubectl get deployment backend-deployment -n ${{ env.NAMESPACE }} &> /dev/null; then
            echo "üîÑ Replacing existing backend-deployment..."
            kubectl replace -f deployments/backend-deployment.yaml -n ${{ env.NAMESPACE }} --force
          else
            echo "üöÄ Creating new backend-deployment..."
            kubectl apply -f deployments/backend-deployment.yaml -n ${{ env.NAMESPACE }}
          fi
          
          if kubectl get deployment frontend-deployment -n ${{ env.NAMESPACE }} &> /dev/null; then
            echo "üîÑ Replacing existing frontend-deployment..."
            kubectl replace -f deployments/frontend-deployment.yaml -n ${{ env.NAMESPACE }} --force
          else
            echo "üöÄ Creating new frontend-deployment..."
            kubectl apply -f deployments/frontend-deployment.yaml -n ${{ env.NAMESPACE }}
          fi

      - name: üîç Check if Migration is Needed
        id: check-migration
        run: |
          # Ê£ÄÊü•ÂΩìÂâçËøêË°åÁöÑ backend ÈïúÂÉè
          CURRENT_BACKEND_IMAGE=$(kubectl get deployment backend-deployment -n ${{ env.NAMESPACE }} -o jsonpath='{.spec.template.spec.containers[0].image}' 2>/dev/null || echo "")
          NEW_BACKEND_IMAGE="${{ needs.build-and-push-images.outputs.backend_image }}"
          
          echo "Current backend image: $CURRENT_BACKEND_IMAGE"
          echo "New backend image: $NEW_BACKEND_IMAGE"
          
          # Â¶ÇÊûúÈïúÂÉèÂèëÁîüÂèòÂåñÊàñËÄÖËøôÊòØÈ¶ñÊ¨°ÈÉ®ÁΩ≤ÔºåÂàôÊâßË°åËøÅÁßª
          if [ "$CURRENT_BACKEND_IMAGE" != "$NEW_BACKEND_IMAGE" ] || [ -z "$CURRENT_BACKEND_IMAGE" ]; then
            echo "üîÑ Backend image changed or first deployment, migration is needed"
            echo "migration_needed=true" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ Backend image unchanged, skipping migration"
            echo "migration_needed=false" >> $GITHUB_OUTPUT
          fi

      - name: üßπ Clean Up Existing Migration Job
        if: steps.check-migration.outputs.migration_needed == 'true'
        run: |
          kubectl delete job db-migration -n ${{ env.NAMESPACE }} --ignore-not-found=true
          sleep 5

      - name: üóÉ Run Database Migrations (if needed)
        if: steps.check-migration.outputs.migration_needed == 'true'
        run: |
          echo "üöÄ Running database migrations..."
          BACKEND_IMAGE="${{ needs.build-and-push-images.outputs.backend_image }}"
          sed "s|PLACEHOLDER_BACKEND_IMAGE|$BACKEND_IMAGE|g" k8s/migrations/db-migration-job.yaml > /tmp/db-migration-job.yaml
          kubectl apply -f /tmp/db-migration-job.yaml

          if kubectl wait --for=condition=complete job/db-migration -n ${{ env.NAMESPACE }} --timeout=300s; then
            MIGRATION_POD=$(kubectl get pods -n ${{ env.NAMESPACE }} -l job-name=db-migration -o jsonpath='{.items[0].metadata.name}')
            echo "‚úÖ Migration completed successfully"
            kubectl logs $MIGRATION_POD -n ${{ env.NAMESPACE }}
            kubectl delete job db-migration -n ${{ env.NAMESPACE }}
          else
            MIGRATION_POD=$(kubectl get pods -n ${{ env.NAMESPACE }} -l job-name=db-migration -o jsonpath='{.items[0].metadata.name}')
            echo "‚ùå Migration failed"
            kubectl logs $MIGRATION_POD -n ${{ env.NAMESPACE }}
            kubectl describe job db-migration -n ${{ env.NAMESPACE }}
            exit 1
          fi

      - name: üîÑ Update Deployment Images
        run: |
          # ‰ΩøÁî® patch Êõ¥Êñ∞ÈïúÂÉèÔºà‰∏ç‰ºöËß¶Âèë selector ‰∏çÂèØÂèòÈîôËØØÔºâ
          BACKEND_IMAGE="${{ needs.build-and-push-images.outputs.backend_image }}"
          FRONTEND_IMAGE="${{ needs.build-and-push-images.outputs.frontend_image }}"
          
          echo "Updating backend deployment image to: $BACKEND_IMAGE"
          kubectl patch deployment backend-deployment -n ${{ env.NAMESPACE }} \
            -p='{"spec":{"template":{"spec":{"containers":[{"name":"backend","image":"'"$BACKEND_IMAGE"'"}]}}}}'
          
          echo "Updating frontend deployment image to: $FRONTEND_IMAGE"
          kubectl patch deployment frontend-deployment -n ${{ env.NAMESPACE }} \
            -p='{"spec":{"template":{"spec":{"containers":[{"name":"frontend","image":"'"$FRONTEND_IMAGE"'"}]}}}}'

      - name: ‚è≥ Wait for Deployments
        run: |
          kubectl rollout status deployment/backend-deployment -n ${{ env.NAMESPACE }} --timeout=300s
          kubectl rollout status deployment/frontend-deployment -n ${{ env.NAMESPACE }} --timeout=180s

      - name: üåê Get ALB URL
        id: get-alb-url
        run: |
          echo "Waiting for ALB to be ready..."
          for i in {1..15}; do
            ALB_HOSTNAME=$(kubectl get ingress comic-website-ingress -n ${{ env.NAMESPACE }} -o=jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || true)
            if [ -n "$ALB_HOSTNAME" ]; then
              echo "‚úÖ ALB is ready!"
              echo "ALB Hostname: $ALB_HOSTNAME"
              echo "Application URL: http://$ALB_HOSTNAME"
              echo "alb_url=http://$ALB_HOSTNAME" >> $GITHUB_OUTPUT
              break
            else
              echo "‚è≥ Attempt $i: ALB not ready yet, waiting 20 seconds..."
              sleep 20
            fi
          done
          
          if [ -z "$ALB_HOSTNAME" ]; then
            echo "‚ùå ALB failed to become ready within timeout period"
            exit 1
          fi

      - name: üì¢ Display Application URL
        run: |
          echo "================================================"
          echo "üöÄ APPLICATION DEPLOYMENT COMPLETE!"
          echo "================================================"
          echo ""
          echo "üåê Your application is now live at:"
          echo "   ${{ steps.get-alb-url.outputs.alb_url }}"
          echo ""
          echo "üìã Additional Information:"
          echo "   - Migration Executed: ${{ steps.check-migration.outputs.migration_needed }}"
          echo "   - Cluster: ${{ env.CLUSTER_NAME }}"
          echo "   - Namespace: ${{ env.NAMESPACE }}"
          echo "   - Region: ${{ env.AWS_REGION }}"
          echo ""
          echo "================================================"