name: Deploy Comic Website

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  CLUSTER_NAME: comic-website-prod
  PROJECT_NAME: comic-website
  ENVIRONMENT: prod
  NAMESPACE: comic-website
  TF_BACKEND_BUCKET: comic-website-tfstate-2024

jobs:
  terraform-infrastructure:
    name: "Terraform - Create Infrastructure"
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0

    - name: Terraform Init
      id: init
      run: |
        cd terraform
        terraform init \
          -backend-config="bucket=${{ env.TF_BACKEND_BUCKET }}" \
          -backend-config="key=terraform/state/terraform.tfstate" \
          -backend-config="region=${{ env.AWS_REGION }}" \
          -backend-config="encrypt=true" \
          -backend-config="dynamodb_table=comic-website-tfstate-lock"

    - name: Terraform Format
      id: fmt
      run: |
        cd terraform
        terraform fmt -check

    - name: Terraform Validate
      id: validate
      run: |
        cd terraform
        terraform validate

    - name: Terraform Plan
      id: plan
      run: |
        cd terraform
        terraform plan \
          -var="aws_region=${{ env.AWS_REGION }}" \
          -var="project_name=${{ env.PROJECT_NAME }}" \
          -var="environment=${{ env.ENVIRONMENT }}" \
          -var="db_password=${{ secrets.DB_PASSWORD }}" \
          -out=tfplan

    - name: Terraform Apply
      if: github.ref == 'refs/heads/main'
      run: |
        cd terraform
        terraform apply -auto-approve tfplan

    - name: Get AWS Account ID
      if: github.ref == 'refs/heads/main'
      run: |
        ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        echo "ACCOUNT_ID=$ACCOUNT_ID" >> $GITHUB_ENV
        echo "AWS Account ID: $ACCOUNT_ID"

    - name: Update kubeconfig
      if: github.ref == 'refs/heads/main'
      run: |
        cd terraform
        aws eks update-kubeconfig \
          --region ${{ env.AWS_REGION }} \
          --name ${{ env.CLUSTER_NAME }}

    - name: Setup Kubernetes tools
      if: github.ref == 'refs/heads/main'
      uses: azure/setup-kubectl@v3
      
    - name: Setup Helm with specific version
      if: github.ref == 'refs/heads/main'
      uses: azure/setup-helm@v3
      with:
        version: '3.12.0'

    - name: Install ALB Ingress Controller with OIDC
      if: github.ref == 'refs/heads/main'
      run: |
        # Add EKS charts repository
        helm repo add eks https://aws.github.io/eks-charts
        helm repo update
        
        # 获取 Terraform 输出
        cd terraform
        VPC_ID=$(terraform output -raw vpc_id)
        ALB_ROLE_ARN=$(terraform output -raw alb_controller_role_arn)
        cd ..
        
        echo "🔧 Creating ALB Controller ServiceAccount with OIDC..."
        
        # 方法1: 使用 printf 创建干净的 YAML 文件
        printf 'apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: aws-load-balancer-controller\n  namespace: kube-system\n  labels:\n    app.kubernetes.io/name: aws-load-balancer-controller\n    app.kubernetes.io/component: controller\n  annotations:\n    eks.amazonaws.com/role-arn: %s\n' "$ALB_ROLE_ARN" > alb-serviceaccount.yaml
        
        # 验证 YAML 文件
        echo "=== YAML 文件内容 ==="
        cat alb-serviceaccount.yaml
        echo "===================="
        
        # 应用 ServiceAccount
        kubectl apply -f alb-serviceaccount.yaml
        
        echo "📝 Creating ALB Controller values file..."
        
        # 创建 Helm values 文件
        cat > alb-values.yaml << 'EOF'
        clusterName: $CLUSTER_NAME
        serviceAccount:
          create: false
          name: aws-load-balancer-controller
        region: $AWS_REGION
        vpcId: $VPC_ID
        image:
          repository: 602401143452.dkr.ecr.$AWS_REGION.amazonaws.com/amazon/aws-load-balancer-controller
        replicaCount: 2
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
        EOF
        
        # 替换变量
        sed -i "s/\$CLUSTER_NAME/$CLUSTER_NAME/g" alb-values.yaml
        sed -i "s/\$AWS_REGION/$AWS_REGION/g" alb-values.yaml
        sed -i "s/\$VPC_ID/$VPC_ID/g" alb-values.yaml
        
        echo "🚀 Installing AWS Load Balancer Controller..."
        
        # 先卸载可能存在的旧版本
        helm uninstall aws-load-balancer-controller -n kube-system 2>/dev/null || true
        
        # 安装新版本
        helm install aws-load-balancer-controller eks/aws-load-balancer-controller \
          -n kube-system \
          -f alb-values.yaml \
          --version 1.6.1 \
          --wait
        
        echo "⏳ Waiting for ALB Controller pods to be ready..."
        sleep 30
        
        # 等待 Pod 就绪
        kubectl wait --for=condition=ready pod \
          -l app.kubernetes.io/name=aws-load-balancer-controller \
          -n kube-system \
          --timeout=300s
        
        echo "✅ ALB Controller installed successfully with OIDC!"
        
        # 清理临时文件
        rm -f alb-serviceaccount.yaml alb-values.yaml

  deploy-applications:
    name: "Deploy Applications to EKS"
    runs-on: ubuntu-latest
    needs: terraform-infrastructure
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Update kubeconfig
      run: |
        aws eks update-kubeconfig \
          --region ${{ env.AWS_REGION }} \
          --name ${{ env.CLUSTER_NAME }}

    - name: Setup Kubernetes tools
      uses: azure/setup-kubectl@v3

    - name: Setup Helm for applications
      uses: azure/setup-helm@v3
      with:
        version: '3.12.0'

    - name: Get Terraform Outputs
      run: |
        cd terraform
        DB_HOST=$(terraform output -raw rds_endpoint)
        S3_BUCKET_NAME=$(terraform output -raw s3_bucket_name)
        BACKEND_ECR_URL=$(terraform output -raw backend_ecr_repository_url)
        FRONTEND_ECR_URL=$(terraform output -raw frontend_ecr_repository_url)
        echo "DB_HOST=$DB_HOST" >> $GITHUB_ENV
        echo "S3_BUCKET_NAME=$S3_BUCKET_NAME" >> $GITHUB_ENV
        echo "BACKEND_ECR_URL=$BACKEND_ECR_URL" >> $GITHUB_ENV
        echo "FRONTEND_ECR_URL=$FRONTEND_ECR_URL" >> $GITHUB_ENV

    - name: Get AWS Account ID
      run: |
        ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
        echo "ACCOUNT_ID=$ACCOUNT_ID" >> $GITHUB_ENV
        echo "AWS Account ID: $ACCOUNT_ID"

    - name: Login to ECR
      run: |
        aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin $ACCOUNT_ID.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com

    - name: Build and Push Backend Docker Image
      run: |
        echo "🏗️ Building backend Docker image..."
        cd backend
        docker build -t $BACKEND_ECR_URL:${GITHUB_SHA:0:8} .
        echo "🚀 Pushing backend image to ECR..."
        docker push $BACKEND_ECR_URL:${GITHUB_SHA:0:8}
        cd ..
        echo "✅ Backend image pushed: $BACKEND_ECR_URL:${GITHUB_SHA:0:8}"

    - name: Build and Push Frontend Docker Image
      run: |
        echo "🏗️ Building frontend Docker image..."
        cd frontend
        docker build -t $FRONTEND_ECR_URL:${GITHUB_SHA:0:8} .
        echo "🚀 Pushing frontend image to ECR..."
        docker push $FRONTEND_ECR_URL:${GITHUB_SHA:0:8}
        cd ..
        echo "✅ Frontend image pushed: $FRONTEND_ECR_URL:${GITHUB_SHA:0:8}"

    - name: Setup Kubernetes Secrets
      run: |
        echo "🔐 Setting up Kubernetes secrets..."
        
        # 创建命名空间（如果不存在）
        kubectl create namespace ${{ env.NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -
        
        # 使用 printf 创建干净的 Secret 文件
        printf 'apiVersion: v1\nkind: Secret\nmetadata:\n  name: rds-secret\n  namespace: %s\ntype: Opaque\nstringData:\n  host: "%s"\n  port: "5432"\n  username: "comicadmin"\n  database: "comicdb"\n  password: "%s"\n' "$NAMESPACE" "$DB_HOST" "${{ secrets.DB_PASSWORD }}" > rds-secret.yaml
        
        printf 'apiVersion: v1\nkind: Secret\nmetadata:\n  name: backend-secrets\n  namespace: %s\ntype: Opaque\nstringData:\n  JWT_SECRET: "%s"\n  AWS_ACCESS_KEY_ID: "%s"\n  AWS_SECRET_ACCESS_KEY: "%s"\n  S3_BUCKET_NAME: "%s"\n' "$NAMESPACE" "${{ secrets.JWT_SECRET || 'default-jwt-secret-change-in-production' }}" "${{ secrets.AWS_ACCESS_KEY_ID }}" "${{ secrets.AWS_SECRET_ACCESS_KEY }}" "$S3_BUCKET_NAME" > backend-secrets.yaml
        
        kubectl apply -f rds-secret.yaml
        kubectl apply -f backend-secrets.yaml
        
        # 清理临时文件
        rm -f rds-secret.yaml backend-secrets.yaml
        
        echo "✅ Kubernetes secrets created successfully"

    - name: Deploy Applications to EKS
      run: |
        echo "🚀 Deploying applications to EKS..."
        
        # 更新部署文件中的镜像标签
        if [ -f "k8s-manifests/deployments/backend-deployment.yaml" ]; then
          sed -i "s|latest|${GITHUB_SHA:0:8}|g" k8s-manifests/deployments/backend-deployment.yaml
        fi
        
        if [ -f "k8s-manifests/deployments/frontend-deployment.yaml" ]; then
          sed -i "s|latest|${GITHUB_SHA:0:8}|g" k8s-manifests/deployments/frontend-deployment.yaml
        fi
        
        # 应用所有 Kubernetes 配置
        if [ -d "k8s-manifests" ]; then
          kubectl apply -k k8s-manifests/
        else
          echo "⚠️ k8s-manifests directory not found, skipping kustomize apply"
        fi
        
        echo "✅ Applications deployed to EKS"

    - name: Wait for Deployments
      run: |
        echo "⏳ Waiting for deployments to be ready..."
        kubectl wait --for=condition=available --timeout=600s deployment/backend-deployment -n ${{ env.NAMESPACE }} || true
        kubectl wait --for=condition=available --timeout=600s deployment/frontend-deployment -n ${{ env.NAMESPACE }} || true
        echo "✅ All deployments are ready"

    - name: Verify Deployment
      run: |
        echo "📊 Deployment Status:"
        echo "=== Deployments ==="
        kubectl get deployments -n ${{ env.NAMESPACE }} || true
        
        echo "=== Pods ==="
        kubectl get pods -n ${{ env.NAMESPACE }} -o wide || true
        
        echo "=== Services ==="
        kubectl get services -n ${{ env.NAMESPACE }} || true
        
        echo "=== Ingress ==="
        kubectl get ingress -n ${{ env.NAMESPACE }} || true

    - name: Health Check
      run: |
        echo "🔍 Performing health check..."
        
        # 等待 ALB 创建
        sleep 30
        
        ALB_URL=$(kubectl get ingress comic-website-ingress -n ${{ env.NAMESPACE }} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "pending")
        
        if [ "$ALB_URL" != "pending" ] && [ "$ALB_URL" != "" ]; then
          echo "🌐 ALB URL: http://$ALB_URL"
          
          # 重试健康检查
          for i in {1..10}; do
            if curl -f http://$ALB_URL/health || curl -f http://$ALB_URL; then
              echo "✅ Health check passed!"
              break
            else
              echo "⚠️ Health check attempt $i failed, retrying in 10 seconds..."
              sleep 10
            fi
          done
        else
          echo "⏰ ALB is still being created, check AWS console for progress"
        fi