name: Deploy Comic Website

on:
  push:
    branches: [main]
  workflow_dispatch:

env:
  AWS_REGION: us-east-1
  CLUSTER_NAME: comic-website-prod
  PROJECT_NAME: comic-website
  ENVIRONMENT: prod
  NAMESPACE: comic-website
  TF_BACKEND_BUCKET: comic-website-tfstate-2024

jobs:
  terraform-infrastructure:
    name: "Terraform - Create Infrastructure"
    runs-on: ubuntu-latest
    environment: production
    outputs:
      backend_ecr_url: ${{ steps.terraform-outputs.outputs.backend_ecr_url }}
      frontend_ecr_url: ${{ steps.terraform-outputs.outputs.frontend_ecr_url }}
      rds_endpoint: ${{ steps.terraform-outputs.outputs.rds_endpoint }}
      rds_port: ${{ steps.terraform-outputs.outputs.rds_port }}
      rds_username: ${{ steps.terraform-outputs.outputs.rds_username }}
      rds_database: ${{ steps.terraform-outputs.outputs.rds_database }}
      alb_controller_role_arn: ${{ steps.terraform-outputs.outputs.alb_controller_role_arn }}
      backend_role_arn: ${{ steps.terraform-outputs.outputs.backend_role_arn }}
      frontend_role_arn: ${{ steps.terraform-outputs.outputs.frontend_role_arn }}

    steps:
      - name: 🧩 Checkout code
        uses: actions/checkout@v4

      - name: 🔑 Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: 🏗 Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: ⚙️ Terraform Init
        run: |
          cd terraform
          terraform init \
            -backend-config="bucket=${{ env.TF_BACKEND_BUCKET }}" \
            -backend-config="key=terraform/state/terraform.tfstate" \
            -backend-config="region=${{ env.AWS_REGION }}" \
            -backend-config="encrypt=true" \
            -backend-config="dynamodb_table=comic-website-tfstate-lock"

      - name: ✅ Terraform Validate
        run: |
          cd terraform
          terraform validate

      - name: 🚀 Terraform Plan and Apply
        run: |
          cd terraform
          terraform plan -out=tfplan \
            -var="aws_region=${{ env.AWS_REGION }}" \
            -var="project_name=${{ env.PROJECT_NAME }}" \
            -var="environment=${{ env.ENVIRONMENT }}" \
            -var="db_password=${{ secrets.DB_PASSWORD }}"
          terraform apply -auto-approve tfplan

      - name: 📋 Get Terraform Outputs
        id: terraform-outputs
        run: |
          cd terraform
          echo "🔍 Getting Terraform outputs..."
          
          terraform output -json > outputs.json
          
          BACKEND_ECR_URL=$(jq -r '.backend_repository_url.value // empty' outputs.json)
          FRONTEND_ECR_URL=$(jq -r '.frontend_repository_url.value // empty' outputs.json)
          RDS_ENDPOINT=$(jq -r '.rds_endpoint.value // empty' outputs.json)
          RDS_PORT=$(jq -r '.rds_port.value // "5432"' outputs.json)
          RDS_USERNAME=$(jq -r '.rds_username.value // "comicadmin"' outputs.json)
          RDS_DATABASE=$(jq -r '.rds_database_name.value // "comicdb"' outputs.json)
          ALB_CONTROLLER_ROLE_ARN=$(jq -r '.alb_controller_role_arn.value // empty' outputs.json)
          BACKEND_ROLE_ARN=$(jq -r '.backend_role_arn.value // empty' outputs.json)
          FRONTEND_ROLE_ARN=$(jq -r '.frontend_role_arn.value // empty' outputs.json)
          
          echo "Backend ECR URL: $BACKEND_ECR_URL"
          echo "Frontend ECR URL: $FRONTEND_ECR_URL"
          echo "RDS Endpoint: $RDS_ENDPOINT"
          echo "RDS Port: $RDS_PORT"
          echo "RDS Username: $RDS_USERNAME"
          echo "RDS Database: $RDS_DATABASE"
          echo "ALB Controller Role ARN: $ALB_CONTROLLER_ROLE_ARN"
          echo "Backend Role ARN: $BACKEND_ROLE_ARN"
          echo "Frontend Role ARN: $FRONTEND_ROLE_ARN"
          
          if [ -z "$BACKEND_ECR_URL" ]; then
            echo "❌ Backend ECR URL is empty"
            exit 1
          fi
          
          if [ -z "$FRONTEND_ECR_URL" ]; then
            echo "❌ Frontend ECR URL is empty"
            exit 1
          fi
          
          if [ -z "$RDS_ENDPOINT" ]; then
            echo "❌ RDS Endpoint is empty"
            exit 1
          fi
          
          if [ -z "$ALB_CONTROLLER_ROLE_ARN" ]; then
            echo "❌ ALB Controller Role ARN is empty"
            exit 1
          fi
          
          if [ -z "$BACKEND_ROLE_ARN" ]; then
            echo "⚠️ Backend Role ARN is empty - backend may not have AWS permissions"
          fi
          
          if [ -z "$FRONTEND_ROLE_ARN" ]; then
            echo "⚠️ Frontend Role ARN is empty - frontend may not have AWS permissions"
          fi
          
          echo "backend_ecr_url=$BACKEND_ECR_URL" >> $GITHUB_OUTPUT
          echo "frontend_ecr_url=$FRONTEND_ECR_URL" >> $GITHUB_OUTPUT
          echo "rds_endpoint=$RDS_ENDPOINT" >> $GITHUB_OUTPUT
          echo "rds_port=$RDS_PORT" >> $GITHUB_OUTPUT
          echo "rds_username=$RDS_USERNAME" >> $GITHUB_OUTPUT
          echo "rds_database=$RDS_DATABASE" >> $GITHUB_OUTPUT
          echo "alb_controller_role_arn=$ALB_CONTROLLER_ROLE_ARN" >> $GITHUB_OUTPUT
          echo "backend_role_arn=$BACKEND_ROLE_ARN" >> $GITHUB_OUTPUT
          echo "frontend_role_arn=$FRONTEND_ROLE_ARN" >> $GITHUB_OUTPUT
          echo "✅ All outputs extracted successfully"

      - name: 🔍 Verify RDS Configuration
        run: |
          echo "🔍 Verifying RDS configuration..."
          aws rds describe-db-instances \
            --region ${{ env.AWS_REGION }} \
            --query 'DBInstances[].{DBInstanceIdentifier:DBInstanceIdentifier, Status:DBInstanceStatus, Endpoint:Endpoint.Address, Port:Endpoint.Port}' \
            --output table

      - name: ☸️ Update kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.CLUSTER_NAME }}

      - name: 🧰 Setup kubectl
        run: |
          sudo snap install kubectl --classic

  build-and-push-images:
    name: "Build and Push Docker Images"
    runs-on: ubuntu-latest
    needs: terraform-infrastructure
    environment: production
    if: needs.terraform-infrastructure.result == 'success'
    
    outputs:
      backend_image: ${{ steps.build-backend.outputs.image_tag }}
      frontend_image: ${{ steps.build-frontend.outputs.image_tag }}

    steps:
      - name: 🧩 Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: 🔑 Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: 🔍 Get AWS Account ID and ECR Registry
        run: |
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          echo "ACCOUNT_ID=$ACCOUNT_ID" >> $GITHUB_ENV
          ECR_REGISTRY="$ACCOUNT_ID.dkr.ecr.${{ env.AWS_REGION }}.amazonaws.com"
          echo "ECR_REGISTRY=$ECR_REGISTRY" >> $GITHUB_ENV

      - name: 🔐 Login to ECR
        run: |
          aws ecr get-login-password --region ${{ env.AWS_REGION }} | docker login --username AWS --password-stdin $ECR_REGISTRY

      - name: 🔍 Set ECR URLs from previous job
        run: |
          echo "BACKEND_ECR_URL=${{ needs.terraform-infrastructure.outputs.backend_ecr_url }}" >> $GITHUB_ENV
          echo "FRONTEND_ECR_URL=${{ needs.terraform-infrastructure.outputs.frontend_ecr_url }}" >> $GITHUB_ENV

      - name: 🏗 Check if Backend Image Exists
        id: check-backend
        run: |
          IMAGE_TAG="${GITHUB_SHA:0:8}"
          BACKEND_IMAGE="$BACKEND_ECR_URL:$IMAGE_TAG"
          if docker manifest inspect $BACKEND_IMAGE > /dev/null 2>&1; then
            echo "image_exists=true" >> $GITHUB_OUTPUT
            echo "image_tag=$BACKEND_IMAGE" >> $GITHUB_OUTPUT
          else
            echo "image_exists=false" >> $GITHUB_OUTPUT
            echo "image_tag=$BACKEND_IMAGE" >> $GITHUB_OUTPUT
          fi

      - name: 🧱 Build Backend Image (if needed)
        id: build-backend
        if: steps.check-backend.outputs.image_exists == 'false'
        run: |
          cd backend
          IMAGE_TAG="${GITHUB_SHA:0:8}"
          BACKEND_IMAGE="$BACKEND_ECR_URL:$IMAGE_TAG"
          docker build -t $BACKEND_IMAGE .
          docker push $BACKEND_IMAGE
          echo "image_tag=$BACKEND_IMAGE" >> $GITHUB_OUTPUT

      - name: 🎨 Build Frontend Image
        id: build-frontend
        run: |
          cd frontend
          IMAGE_TAG="${GITHUB_SHA:0:8}"
          FRONTEND_IMAGE="$FRONTEND_ECR_URL:$IMAGE_TAG"
          docker build -t $FRONTEND_IMAGE .
          docker push $FRONTEND_IMAGE
          echo "image_tag=$FRONTEND_IMAGE" >> $GITHUB_OUTPUT

  deploy-applications:
    name: "Deploy Applications to EKS"
    runs-on: ubuntu-latest
    needs: 
      - terraform-infrastructure
      - build-and-push-images
    environment: production
    if: needs.terraform-infrastructure.result == 'success'

    steps:
      - name: 🧩 Checkout code
        uses: actions/checkout@v4

      - name: 🔑 Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: 🔍 Debug Job Outputs
        run: |
          echo "🔍 Debugging job outputs..."
          echo "terraform-infrastructure outputs:"
          echo "  backend_ecr_url: ${{ needs.terraform-infrastructure.outputs.backend_ecr_url }}"
          echo "  frontend_ecr_url: ${{ needs.terraform-infrastructure.outputs.frontend_ecr_url }}"
          echo "  rds_endpoint: ${{ needs.terraform-infrastructure.outputs.rds_endpoint }}"
          echo "  rds_port: ${{ needs.terraform-infrastructure.outputs.rds_port }}"
          echo "  rds_username: ${{ needs.terraform-infrastructure.outputs.rds_username }}"
          echo "  rds_database: ${{ needs.terraform-infrastructure.outputs.rds_database }}"
          echo "  alb_controller_role_arn: ${{ needs.terraform-infrastructure.outputs.alb_controller_role_arn }}"
          echo "  backend_role_arn: ${{ needs.terraform-infrastructure.outputs.backend_role_arn }}"
          echo "  frontend_role_arn: ${{ needs.terraform-infrastructure.outputs.frontend_role_arn }}"
          
          echo "build-and-push-images outputs:"
          echo "  backend_image: ${{ needs.build-and-push-images.outputs.backend_image }}"
          echo "  frontend_image: ${{ needs.build-and-push-images.outputs.frontend_image }}"

      - name: 🔍 Set Deployment Variables
        run: |
          # 直接从 job 输出设置变量
          BACKEND_IMAGE="${{ needs.build-and-push-images.outputs.backend_image }}"
          FRONTEND_IMAGE="${{ needs.build-and-push-images.outputs.frontend_image }}"
          RDS_ENDPOINT="${{ needs.terraform-infrastructure.outputs.rds_endpoint }}"
          RDS_PORT="${{ needs.terraform-infrastructure.outputs.rds_port }}"
          RDS_USERNAME="${{ needs.terraform-infrastructure.outputs.rds_username }}"
          RDS_DATABASE="${{ needs.terraform-infrastructure.outputs.rds_database }}"
          ALB_CONTROLLER_ROLE_ARN="${{ needs.terraform-infrastructure.outputs.alb_controller_role_arn }}"
          BACKEND_ROLE_ARN="${{ needs.terraform-infrastructure.outputs.backend_role_arn }}"
          FRONTEND_ROLE_ARN="${{ needs.terraform-infrastructure.outputs.frontend_role_arn }}"
          
          echo "BACKEND_IMAGE=$BACKEND_IMAGE" >> $GITHUB_ENV
          echo "FRONTEND_IMAGE=$FRONTEND_IMAGE" >> $GITHUB_ENV
          echo "RDS_ENDPOINT=$RDS_ENDPOINT" >> $GITHUB_ENV
          echo "RDS_PORT=$RDS_PORT" >> $GITHUB_ENV
          echo "RDS_USERNAME=$RDS_USERNAME" >> $GITHUB_ENV
          echo "RDS_DATABASE=$RDS_DATABASE" >> $GITHUB_ENV
          echo "ALB_CONTROLLER_ROLE_ARN=$ALB_CONTROLLER_ROLE_ARN" >> $GITHUB_ENV
          echo "BACKEND_ROLE_ARN=$BACKEND_ROLE_ARN" >> $GITHUB_ENV
          echo "FRONTEND_ROLE_ARN=$FRONTEND_ROLE_ARN" >> $GITHUB_ENV
          
          # 清理 RDS 端点（移除端口部分）
          CLEANED_RDS_ENDPOINT=$(echo "$RDS_ENDPOINT" | cut -d':' -f1)
          echo "RDS_ENDPOINT_CLEANED=$CLEANED_RDS_ENDPOINT" >> $GITHUB_ENV
          
          # 设置前端 URL
          FRONTEND_URL="http://comic-website-alb-123456789.us-east-1.elb.amazonaws.com"
          echo "FRONTEND_URL=$FRONTEND_URL" >> $GITHUB_ENV

          echo "✅ Deployment variables set:"
          echo "  BACKEND_IMAGE: $BACKEND_IMAGE"
          echo "  FRONTEND_IMAGE: $FRONTEND_IMAGE"
          echo "  RDS_ENDPOINT: $RDS_ENDPOINT"
          echo "  RDS_ENDPOINT_CLEANED: $CLEANED_RDS_ENDPOINT"
          echo "  RDS_PORT: $RDS_PORT"
          echo "  RDS_USERNAME: $RDS_USERNAME"
          echo "  RDS_DATABASE: $RDS_DATABASE"
          echo "  ALB_CONTROLLER_ROLE_ARN: $ALB_CONTROLLER_ROLE_ARN"
          echo "  BACKEND_ROLE_ARN: $BACKEND_ROLE_ARN"
          echo "  FRONTEND_ROLE_ARN: $FRONTEND_ROLE_ARN"
          echo "  FRONTEND_URL: $FRONTEND_URL"

      - name: ☸️ Update kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.CLUSTER_NAME }}

      - name: 🧰 Setup kubectl
        run: |
          sudo snap install kubectl --classic

      - name: 🔧 Configure All Service Accounts with Dynamic IAM Roles
        run: |
          echo "🔧 Configuring all Service Accounts with dynamic IAM Roles..."
          
          # ALB Controller Service Account
          ALB_ROLE_ARN="${{ needs.terraform-infrastructure.outputs.alb_controller_role_arn }}"
          if [ -n "$ALB_ROLE_ARN" ]; then
            echo "📝 Configuring ALB Controller Service Account..."
            kubectl apply -f - <<EOF
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: aws-load-balancer-controller
              namespace: kube-system
              labels:
                app.kubernetes.io/name: aws-load-balancer-controller
                app.kubernetes.io/component: controller
              annotations:
                eks.amazonaws.com/role-arn: "$ALB_ROLE_ARN"
                eks.amazonaws.com/sts-regional-endpoints: "true"
            EOF
            echo "✅ ALB Controller Service Account configured"
          else
            echo "❌ ALB Role ARN is empty"
            exit 1
          fi
          
          # Backend Service Account
          BACKEND_ROLE_ARN="${{ needs.terraform-infrastructure.outputs.backend_role_arn }}"
          if [ -n "$BACKEND_ROLE_ARN" ]; then
            echo "📝 Configuring Backend Service Account..."
            kubectl apply -f - <<EOF
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: comic-backend-sa
              namespace: ${{ env.NAMESPACE }}
              annotations:
                eks.amazonaws.com/role-arn: "$BACKEND_ROLE_ARN"
            EOF
            echo "✅ Backend Service Account configured"
          else
            echo "⚠️ Backend Role ARN is empty - backend may not have AWS permissions"
          fi
          
          # Frontend Service Account
          FRONTEND_ROLE_ARN="${{ needs.terraform-infrastructure.outputs.frontend_role_arn }}"
          if [ -n "$FRONTEND_ROLE_ARN" ]; then
            echo "📝 Configuring Frontend Service Account..."
            kubectl apply -f - <<EOF
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: comic-frontend-sa
              namespace: ${{ env.NAMESPACE }}
              annotations:
                eks.amazonaws.com/role-arn: "$FRONTEND_ROLE_ARN"
            EOF
            echo "✅ Frontend Service Account configured"
          else
            echo "⚠️ Frontend Role ARN is empty - frontend may not have AWS permissions"
          fi
          
          # 重启相关部署以应用新的 Service Account
          echo "🔄 Restarting deployments to use new Service Accounts..."
          kubectl rollout restart deployment -n kube-system aws-load-balancer-controller
          kubectl rollout restart deployment -n ${{ env.NAMESPACE }} backend-deployment
          kubectl rollout restart deployment -n ${{ env.NAMESPACE }} frontend-deployment
          
          echo "⏳ Waiting for deployments to be ready..."
          kubectl rollout status deployment -n kube-system aws-load-balancer-controller --timeout=180s
          kubectl rollout status deployment -n ${{ env.NAMESPACE }} backend-deployment --timeout=180s
          kubectl rollout status deployment -n ${{ env.NAMESPACE }} frontend-deployment --timeout=180s
          
          echo "✅ All Service Accounts configured successfully"

      - name: 🗃 Create Namespace
        run: |
          kubectl create namespace ${{ env.NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

      - name: 🚀 Deploy using Kustomize (excluding Service Accounts)
        run: |
          echo "🚀 Applying all manifests using Kustomize (excluding Service Accounts)..."
          cd k8s
          
          # 使用 Kustomize 部署除 Service Accounts 外的所有资源
          # 因为 Service Accounts 已经在前面步骤中动态创建了
          kubectl apply -k . --namespace ${{ env.NAMESPACE }}
          echo "✅ Kustomize deployment completed"

      - name: 🔄 Update Backend Image
        run: |
          echo "🔄 Updating backend image to: $BACKEND_IMAGE"
          kubectl set image deployment/backend-deployment backend=$BACKEND_IMAGE -n ${{ env.NAMESPACE }}
          echo "✅ Backend image updated"

      - name: 🔄 Update Frontend Image
        run: |
          echo "🔄 Updating frontend image to: $FRONTEND_IMAGE"
          kubectl set image deployment/frontend-deployment frontend=$FRONTEND_IMAGE -n ${{ env.NAMESPACE }}
          echo "✅ Frontend image updated"

      - name: 🎯 Set Backend Environment Variables
        run: |
          echo "🎯 Setting backend environment variables..."
          echo "RDS_ENDPOINT_CLEANED: $RDS_ENDPOINT_CLEANED"
          echo "RDS_PORT: $RDS_PORT"
          echo "RDS_DATABASE: $RDS_DATABASE"
          echo "RDS_USERNAME: $RDS_USERNAME"
          echo "DB_PASSWORD from secrets: ${{ secrets.DB_PASSWORD != '' && '***SET***' || '***EMPTY***' }}"
          
          # 验证关键环境变量
          if [ -z "$RDS_ENDPOINT_CLEANED" ]; then
            echo "❌ ERROR: RDS_ENDPOINT_CLEANED is empty"
            exit 1
          fi
          
          if [ -z "${{ secrets.DB_PASSWORD }}" ]; then
            echo "❌ ERROR: DB_PASSWORD secret is empty"
            echo "Please check if DB_PASSWORD is set in GitHub Secrets"
            exit 1
          fi
          
          echo "✅ All environment variables are valid"
          
          # 设置数据库环境变量 - 直接使用 GitHub Secrets
          kubectl set env deployment/backend-deployment -n ${{ env.NAMESPACE }} \
            DB_HOST="$RDS_ENDPOINT_CLEANED" \
            DB_PORT="$RDS_PORT" \
            DB_NAME="$RDS_DATABASE" \
            DB_USER="$RDS_USERNAME" \
            DB_PASSWORD="${{ secrets.DB_PASSWORD }}"
          
          echo "✅ Database environment variables set"
          
          # 设置其他环境变量
          kubectl set env deployment/backend-deployment -n ${{ env.NAMESPACE }} \
            NODE_ENV=production \
            PORT=3000 \
            FRONTEND_URL="$FRONTEND_URL" \
            JWT_SECRET="${{ secrets.JWT_SECRET }}" \
            JWT_EXPIRES_IN="7d" \
            AWS_REGION="${{ env.AWS_REGION }}" \
            AWS_ACCESS_KEY_ID="${{ secrets.AWS_ACCESS_KEY_ID }}" \
            AWS_SECRET_ACCESS_KEY="${{ secrets.AWS_SECRET_ACCESS_KEY }}" \
            S3_BUCKET_NAME="${{ secrets.S3_BUCKET_NAME }}"
          
          echo "✅ All environment variables set successfully"

      - name: 🔍 Verify Service Account Configurations
        run: |
          echo "🔍 Verifying Service Account configurations..."
          
          echo "=== ALB Controller Service Account ==="
          kubectl get serviceaccount -n kube-system aws-load-balancer-controller -o yaml | grep -A 2 annotations
          
          echo "=== Backend Service Account ==="
          kubectl get serviceaccount -n ${{ env.NAMESPACE }} comic-backend-sa -o yaml | grep -A 2 annotations || echo "Backend Service Account not found"
          
          echo "=== Frontend Service Account ==="
          kubectl get serviceaccount -n ${{ env.NAMESPACE }} comic-frontend-sa -o yaml | grep -A 2 annotations || echo "Frontend Service Account not found"

      - name: 🔍 Verify Environment Variables
        run: |
          echo "🔍 Verifying environment variables in deployment..."
          sleep 10
          
          # 检查 deployment 的环境变量配置
          echo "=== Deployment Environment Variables ==="
          kubectl get deployment backend-deployment -n ${{ env.NAMESPACE }} -o jsonpath='{.spec.template.spec.containers[0].env}' | jq .
          
          # 等待 pod 启动并检查实际环境变量
          echo "=== Waiting for pod to be ready ==="
          kubectl rollout status deployment/backend-deployment -n ${{ env.NAMESPACE }} --timeout=120s || true
          
          BACKEND_POD=$(kubectl get pods -n ${{ env.NAMESPACE }} -l app=backend -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$BACKEND_POD" ]; then
            echo "=== Actual Pod Environment Variables ==="
            kubectl exec $BACKEND_POD -n ${{ env.NAMESPACE }} -- env | grep -E "(DB_|NODE_ENV|PORT)" || echo "Pod not ready yet"
          else
            echo "❌ No backend pod found"
          fi

      - name: ⏳ Wait for Deployments
        run: |
          echo "🔎 Waiting for deployments to be ready..."
          timeout 300s bash -c "
            while ! kubectl rollout status deployment/backend-deployment -n ${{ env.NAMESPACE }} --timeout=60s 2>/dev/null; do
              echo '⏳ Backend still deploying...'
              sleep 10
            done
          " || echo "⚠️ Backend deployment timeout, continuing..."

          timeout 180s bash -c "
            while ! kubectl rollout status deployment/frontend-deployment -n ${{ env.NAMESPACE }} --timeout=60s 2>/dev/null; then
              echo '⏳ Frontend still deploying...'
              sleep 10
            done
          " || echo "⚠️ Frontend deployment timeout, continuing..."

      - name: 🌐 Check ALB Controller Status
        run: |
          echo "🌐 Checking ALB Controller status..."
          echo "=== ALB Controller Pods ==="
          kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller
          
          echo "=== ALB Controller Logs ==="
          kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --tail=20 || true
          
          echo "=== Ingress Status ==="
          kubectl get ingress -n ${{ env.NAMESPACE }} -o wide

      - name: 📊 Final Deployment Status
        run: |
          echo "📊 Final deployment status:"
          kubectl get pods -n ${{ env.NAMESPACE }}
          
          echo -e "\n📋 Services:"
          kubectl get svc -n ${{ env.NAMESPACE }}
          
          echo -e "\n🌐 Ingress:"
          kubectl get ingress -n ${{ env.NAMESPACE }} -o yaml | grep -A 10 "status:"

      - name: 🔍 Check Application Logs
        run: |
          echo "🔍 Checking backend logs..."
          BACKEND_POD=$(kubectl get pods -n ${{ env.NAMESPACE }} -l app=backend -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
          if [ -n "$BACKEND_POD" ]; then
            echo "=== Backend Logs ==="
            kubectl logs $BACKEND_POD -n ${{ env.NAMESPACE }} --tail=50 || true
          else
            echo "❌ No backend pod found"
          fi

      - name: 🌐 Get ALB URL
        run: |
          echo "🚀 Retrieving ALB URL..."
          for i in {1..15}; do
            ALB_URL=$(kubectl get ingress comic-website-ingress -n ${{ env.NAMESPACE }} -o=jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || true)
            if [ -n "$ALB_URL" ]; then
              echo "✅ ALB is ready: http://$ALB_URL"
              echo "ALB_URL=http://$ALB_URL" >> $GITHUB_ENV
              break
            fi
            echo "⏳ ALB not ready yet (attempt $i/15)..."
            sleep 20
          done
          
          if [ -z "$ALB_URL" ]; then
            echo "❌ ALB creation failed after 15 attempts"
            echo "🔍 Checking ALB Controller logs for details..."
            kubectl logs -n kube-system -l app.kubernetes.io/name=aws-load-balancer-controller --tail=50
            echo "🔍 Checking Ingress events..."
            kubectl describe ingress comic-website-ingress -n ${{ env.NAMESPACE }}
            exit 1
          fi